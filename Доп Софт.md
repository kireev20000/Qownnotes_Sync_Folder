Доп Софт
========================

## Что такое lru cache

- [LRU, метод вытеснения из кэша](https://habr.com/ru/post/136758/)

LRU (least recently used) — это алгоритм, при котором вытесняются значения, которые дольше всего не запрашивались. Соответственно, необходимо хранить время последнего запроса к значению. И как только число закэшированных значений превосходит N необходимо вытеснить из кеша значение, которое дольше всего не запрашивалось.

## Какие вы знаете инструменты для проверки кодстайл

- [Инструменты для анализа кода Python. Часть 1](https://proglib.io/p/python-code-analysis/)
- [Инструменты для анализа кода Python. Часть 2](https://proglib.io/p/python-code-analysis-tools/)

**Pycodestyle** — простая консольная утилита для анализа кода Python, а именно для проверки кода на соответствие PEP8. Один из старейших анализаторов кода, до 2016 года носил название pep8, но был переименован по просьбе создателя языка Python Гвидо ван Россума.

**Pydocstyle** проверяет наличие docstring у модулей, классов, функций и их соответствие официальному соглашению PEP257.

**Pylint** совместил в себе как поиск логических так и стилистических ошибок. Этот мощный, гибко настраиваемый инструмент для анализа кода Python отличается большим количеством проверок и разнообразием отчетов.

**Vulture** — небольшая утилита для поиска “мертвого” кода в программах Python. Она использует модуль ast стандартной библиотеки и создает абстрактные синтаксические деревья для всех файлов исходного кода в проекте. Далее осуществляется поиск всех объектов, которые были определены, но не используются. Vulture полезно применять для очистки и нахождения ошибок в больших базовых кодах.

**Flake8** — обвязка к входящим в нее утилитам — pyflakes, pycodestyle, mccabe. Flake8 имеет схожий с pylint основной функционал. Однако она имеет ряд отличий и особенностей:

- Возможности статистических отчетов ограничены подсчетом количества каждой из ошибок (—statistics) и их общим количеством (—count).
- Для запуска в несколько потоков (`—jobs=<num>`) используется модуль multiprocessing, по этой причине многопоточность не будет работать на Windows системах.
- Отсутствует возможность генерации отчетов в формате json, при вызове с ключом —bug-report создается только заголовок для отчета с указанием платформы и версий входящих утилит.
- Комментарии в коде блокирующие вывод. Добавление в строку с ошибкой комментария # noqa, уберет ее из отчета.
- Во время редактирования для подавления отдельных ошибок “на лету” можно перечислить исключаемые ошибки в ключе `—extend-ignore=<errors>`
- Проверка синтаксиса в строках doctest (—doctests).
- Наличие Version Control Hooks. Интеграция с системами контроля версий происходит буквально с помощью двух команд (поддерживаются git и mercurial).
- Расширяемость. Flake8 для анализа кода Python позволяет создавать и использовать плагины. С помощью плагинов в Flake8 можно: добавить дополнительные проверки, использовать другие форматы отчетов или автоматически исправлять найденные ошибки. На PyPi можно найти большое количество open-source плагинов.

**Prospector** — это инструмент для анализа кода Python. Объединяет функциональность других инструментов анализа Python, таких как pylint, pep8, mccabe, Pyflakes, Dodgy, pydocstyle (экспериментально, возможны ошибки). Дополнительно можно подключить mypy, pyroma, vulture. Главной особенностью prospector является наличие предустановленных профилей, которые содержат настройки входящих в него утилит, призванных подавить наиболее придирчивые предупреждения и оставить только важные сообщения.

**Pylama** — инструмент аудита кода для Python и JavaScript. Служит оберткой на такими утилитами как: pydocstyle, pycodestyle, pyflakes, mccabe, pylint, radon (инструмент для сбора и вычисления различных метрик из исходного кода). Для работы с работы с JavaScript кодом используется gjslint.

**autopep8** модифицирует код, не совместимый с PEP8. Проверка соответствия соглашениям осуществляется с помощью утилиты pycodestyle. В autopep8 есть поддержка многопоточности, рекурсивного обхода каталогов, возможность сохранения настроек в файле, задание диапазона строк для исправления, фильтрация ошибок и непосредственное изменение проверяемого файла.

**yapf** похож на autopep8, но использует другой подход, который основан на «clang-format», разработанном Дэниелом Джаспером. Отформатированный yapf код, будет не только соблюдать принятые соглашения, но и выглядеть так, словно был написан хорошим программистом. Вторым важным отличием является возможность задавать стили. Для этого воспользуйтесь ключом —style и в качестве аргумента передайте файл с настройками или одно из предопределенных значений (pep8, google, chromium, facebook).

**black** — это бескомпромиссный форматировщик, который работает быстро и экономит время и умственную энергию программистов для более важных вопросов.


# Что такое MQ

[Межсервисное взаимодействие. Очереди сообщений - YouTube](https://www.youtube.com/watch?v=zdKziDsFjvg)

Очереди сообщений, по существу, являются связующим звеном между различными процессами в ваших приложениях и обеспечивают надежный и масштабируемый интерфейс взаимодействия с другими подключенными системами и устройствами.

О́чередь — структура данных с дисциплиной доступа к элементам «первый пришёл — первый вышел». Добавление элемента возможно лишь в конец очереди, выборка — только из начала очереди, при этом выбранный элемент из очереди удаляется.

нужно определиться зачем вообще они нужны?

1. Для отложенных операций. Классическим примером является обработка картинок. К примеру пользователь загрузил на сайт картинку, которую нам нужно обработать, эта операция занимает много времени, пользователь столько ждать не хочет. Поэтому мы грузим картинку, далее передаем ее в очередь. И она будет обработана, когда какой либо «worker» ее достанет.

2. Для обработки пиковых нагрузок. К примеру, есть какая-то часть системы, на которую иногда обрушивается большой трафик и она не требует мгновенного ответа. Как вариант, генерация каких-либо отчетов. Выкидывая в очередь эту задачу — мы даем возможность обрабатывать это с равномерной нагрузкой на систему.

3. Масштабируемость. И наверное самая важная причина, очередь дает возможность
масштабироваться. Это означает, что вы можете поднять несколько сервисов для обработки параллельно, что сильно повысит производительность.

Теперь давайте рассмотрим проблемы, с которыми столкнемся, если будем создавать очередь сами:

1. Параллельный доступ. Забрать из очереди определенное сообщение может только один обработчик. То есть если одновременно два сервиса попросят сообщения, каждому из них должен вернуться уникальный набор сообщений. Иначе, получится, что одно сообщение обработается два раза. Что может быть чревато.

2. Механизм дедупликации. В сервисе должна быть система, защищающая очередь от дубликатов. Может быть ситуация, в которой случайно в очередь будет отправлено один и тот-же набор данных два раза. В итоге мы одно и тоже обработаем два раза. Что опять же чревато.

3. Механизм обработки ошибок. Допустим наш сервис забрал из очереди три сообщения. Два из которых он успешно обработал, отправив запросы на удаление из очереди. А третье он не смог обработать и умер. Сообщение которое находится в статусе обработки — недоступно для других сервисов. И оно не должно навечно остаться в статусе обработки. Такое сообщение должно передаться другому обработчику по какой-то логике. Вариант реализации такой логики мы рассмотрим скоро на примере AWS SQS(Simple Queue Service)
4. 

``AMQP (Advanced Message Queuing Protocol) — открытый протокол для передачи сообщений между компонентами системы. Основная идея состоит в том, что отдельные подсистемы (или независимые приложения) могут обмениваться произвольным образом сообщениями через AMQP-брокер, который осуществляет маршрутизацию, возможно гарантирует доставку, распределение потоков данных, подписку на нужные типы сообщений.``

Протокол AMQP вводит три понятия:

1. exchange (обменник или точка обмена) — в неё отправляются сообщения. Обменник распределяет сообщение в одну или несколько очередей. Он маршрутизирует сообщения в очередь на основе созданных связей (binding) между ним и очередью
2. queue (очередь) — структура данных на диске или в оперативной памяти, которая хранит ссылки на сообщения и отдает копии сообщений consumers (потребителям). Одна очередь может использоваться несколькими потребителями
3. binding (привязка) — правило, которое сообщает точке обмена в какую из очередей эти сообщения должны попадать. Обменник и очередь могут быть связаны несколькими привязками

### Где используется RabbitMQ?

В контексте микросервисов протокол AMQP и его реализацию в RabbitMQ часто используют для асинхронного взаимодействия между сервисами.

---
Десять причин, почему очереди сообщений являются жизненно важным компонентом для любой архитектуры или приложения:

- *Слабое связывание* — очереди сообщений создают неявные интерфейсы обмена данными, которые позволяют процессам быть независимыми друг от друга т.е вы просто определяете формат сообщений отправляемых от одного процесса другому.
- *Избыточность* — Очереди позволяют избежать случаев неэкономного использования ресурсов процесса(например памяти) в результате хранения необработанной (лишней) информации.
- *Масштабируемость* — очереди сообщений позволяют распределить процессы обработки информации. Таким образом, они позволяют легко наращивать скорость, с которой сообщения добавляются в очередь и обрабатываются.
- *Эластичность и возможность выдерживать пиковые нагрузки* — очереди сообщений могут выполнять роль своего рода буфера для накопления данных в случае пиковой нагрузки, смягчая тем самым нагрузку на систему обработки информации и не допуская ее отказа.
- *Отказоустойчивость* — очереди сообщений позволяют отделить процессы друг от друга, так что если процесс, который обрабатывает сообщения из очереди падает, то сообщения могут быть добавлены в очередь на обработку позднее, когда система восстановится.
- *Гарантированная доставка* — использование очереди сообщений гарантирует, что сообщение будет доставлено и обработано в любом случае (пока есть хотя бы один обработчик).
- *Гарантированный порядок доставки* — большая часть систем очередей сообщений способны обеспечить гарантии того, что данные будут обрабатываться в определённом порядке (чаще всего в том порядке в котором они поступили).
- *Буферизация* — очереди сообщений позволяет отправлять и получать сообщения при этом работая с максимальной эффективностью, предлагая буферный слой — процесс записи в очередь может происходить настолько быстро, насколько быстро это в состоянии выполнить очередь сообщений, а не обработчик сообщения.
- *Понимание потоков данных* — очереди сообщений позволяют выявлять узкие места в потоках данных приложения, легко можно определить какая из очередей забивается, какая простаивает и определить что необходимо делать — добавлять новых обработчиков сообщений или оптимизировать текущую архитектуру.
- *Асинхронная связь* — очереди сообщений предоставляют возможность асинхронной обработки данных, которая позволяет поместить сообщение в очередь без обработки, позволяя системе обработать сообщение позднее, когда появится возможность.

## Какие готовые реализации MQ вы знаете

- [Message middleware deployment and comparison: rabbitMQ, activeMQ, zeroMQ, rocketMQ, Kafka, redis](http://www.programmersought.com/article/3359645442/)
- [RabbitMQ против Kafka: два разных подхода к обмену сообщениями](https://habr.com/ru/company/itsumma/blog/416629/)
- [Kafka VS RabbitMQ](https://medium.com/@vozerov/kafka-vs-rabbitmq-38e221cf511b)
- [Выбор MQ для высоконагруженного проекта](https://habr.com/ru/post/326880/)

[Очереди — что это, зачем и как использовать? Посмотрим на возможности AWS SQS / Хабр](https://habr.com/ru/articles/457068/)
- ActiveMQ
- RabbitMQ
- RedisQueue
- Kafka
- rocketMQ
- zeroMQ




# Git (VCS)

Система контроля версий (от англ. Version Control System, VCS) — это место хранения кода.

## Что такое local и remote репозитории?
Локал тот что на ПК разработчика, а удаленный хранится в интернете.

---
## Что такое commit?
Каждый комит — набор изменений.

---
## Что такое ветка?
Под веткой принято понимать независимую последовательность коммитов в хронологическом порядке. 

---
## Что такое pull-request / merge-request?

---
### Что такое git fetch
Чтобы получить изменения из удаленного репозитория, в Git предусмотрена команда git fetch.
```
git fetch origin
```
## Что такое pull?

Получает изменения из переданного удаленного репозитория и обновляет рабочую копию в соответствии с удаленным репозиторием. 
По факту данная команда аналогична связке git fetch + git merge, но выполненной из удаленного репозитория (это просто аналогия, на самом деле так сделать не получится).

## Чем rebase отличается от merge?

Команда git merge объединяет несколько последовательностей коммитов в общую историю. Чаще всего команду git merge используют для объединения двух веток.

Rebase — это наложение коммитов поверх другого базового коммита. Под базовым понимается тот коммит, к которому применяются коммиты выбранной ветки.


`git rebase` — еще один способ перенести изменения из одной ветки в другую. Rebase сжимает все изменения в один «патч». Затем он интегрирует патч в целевую ветку.
В отличие от слияния, перемещение перезаписывает историю, потому что она передает завершенную работу из одной ветки в другую. В процессе устраняется нежелательная история.


rebase нужен для порядка (линейность истории), чтоб потом смотреть и понимать. rebase переносит коммиты поверх того, что было в результирующей ветке. merge оставляет коммиты, как есть, просто добавляя связующий коммит между ветками.


## Что такое конфликты? Почему они возникают и как их разрешать?

 Конфликт возникает, когда в двух ветках была изменена одна и та же строка в файле или когда некий файл удален в одной ветке и отредактирован в другой. Как правило, конфликты возникают при работе в команде.
 

- [Git - Book](https://git-scm.com/book/ru/v2)



## Что такое Git Rebase

Итак git работает с комитами. Каждый комит — набор изменений. У каждого комита есть уникальный hash. Когда происходит слияние веток посредством merge:

`$ git merge "another_branch"`

то все комиты сохраняются — сохраняются комментарии комита, его hash + как правило добавляется еще один искусственный комит. При этом комиты могут чередоваться друг с другом. Это не всегда удобно. Допустим ваш комит решили откатить — выискивать в общем списке где ваш комит, а где не ваш не очень приятно. И вообще — в общей истории хочется видеть действительно важные изменения, а не «ой, я забыл поставить ;». Для того, чтобы несколько комитов склеивать в один можно использовать rebase. Хотя в интерфейсе GitHub есть кнопочка squash & commit — это когда вы создаете pull request (PR) из одной ветки в другую (как правило из вашей рабочей ветки в основную) и после прохождения всех формальностей можно нажать squash & commit, обновить комментарий и ваши изменения появятся в основной ветке как один комит.

Хочу написать о двух случаях использования rebase:

1. Когда изменения включаются из одну ветку в другую не посредством merge, а посредством rebase:
    `$ git rebase "another_branch"`
    Это позволяет ваши локальные комиты поставить после всех комитов, которые были внесены в ветку «another_branch». Хэши ваших комитов изменятся.
2. Когда можно руками отредактировать несколько ваших комитов — например склеить их, изменить коментарий:
    `$ git rebase -i {HEAD~_commit_count_|commit_hash}`

Итак вы все сделали в своей уютненькой веточки и решили поделиться этим комитом с миром, но мир хочет от вас только один комит. `git rebase -i` запустит редактор и предложит отредактировать комиты (порядок следования комитов — сверху вниз в отличие от git log). Можно оставить комит как есть, можно изменить комментарий, можно склеить с предыдущим. Как правило ваш первый комит надо оставить как есть, а все остальные изменить на
`pick "commit_hash" "comment" → fixup "commit_hash" "comment"`.

При этом все комментарии, которые были в fixup комитах потеряются и будет использоваться комментарий от первого комита. Если вам были дороги комментарии, то стоит использовать squash вместо fixup.

Но если процесс разработки был долог, то скорее всего вам приходилось делать merge основной ветки. И все ваши комиты перемешаются с общими комитами и склеивать ваши с не вашими будет задачей непростой. Поэтому перед тем, как делать `git rebase -i <>` стоит сделать `git rebase`. `git rebase` поставит все ваши комиты в конец списка всех комитов (в чем можно убедиться запустив `git log`) и после этого запустиь `git rebase -i <HEAD~Количесво_ваших_комитов>`, во всех строчках кроме первой заменить pick → {fixup|squash} и вуаля — у вас один комит.

Если в процессе редактирования комитов `git rebase -i <>` вы как-то накосячили, то не стоит жать Control+C — exit code выхода из редактора git не волнует. Он просто возьмет файл и сделает все по нему. Просто удалите или закомментируйте все строчки в файле. git поймет, что вы ничего не хотели.

После манипуляций с rebase потребуется push с опцией -F. Все это потому, что мы переписываем меняем историю комитов и git нас об этом честно предупреждает.
`$ git push -f`

## Что такое Git Cherry pick

Команда `git cherry-pick` используется для перенесения отдельных коммитов из одного места репозитория в другое, обычно между ветками разработки и обслуживания. Этот механизм отличается от привычных команд `git merge` и `git rebase`, которые переносят коммиты целыми цепочками.

`git cherry-pick <commit-hash>`

## Что такое force push

Если вы поправили какие-нибудь старые коммиты в истории git, например: исправили имя автора или e-mail, или отменили последний коммит или воспользовались amend или revert, то при попытке push-а git справедливо «ругнётся»

Чтобы нам всё же запушить наши изменения, нам нужно выполнить либо

`git push --force origin <имя_ветки>`

Но в этом случае мы рискуем перетереть чьи-нибудь изменения, если с тех пор, как мы забирали изменения с сервера, кто-то успел запушить свои коммиты. Поэтому лучше использовать более безопасную команду:

`git push --force-with-lease origin <имя_ветки>`

Такой вариант лучше тем, что если кто-то успел запушить свои коммиты после того, как мы забирали изменения с сервера, то он не будет их перетирать, а выдаст нам ошибку, после чего мы сможем интегрировать чужие коммиты со своими изменениями и попытаться сделать `push --force-with-lease` ещё раз.

## Что такое pre-commit check

Как и во многих других системах контроля версий, в Git'е есть возможность запускать собственные сценарии в те моменты, когда происходят некоторые важные действия. Существуют две группы подобных перехватчиков (hook): на стороне клиента и на стороне сервера. Перехватчики на стороне клиента предназначены для клиентских операций, таких как создание коммита и слияние. Перехватчики на стороне сервера нужны для серверных операций, таких как приём отправленных коммитов. Перехватчики могут быть использованы для выполнения самых различных задач. О некоторых из таких задач мы и поговорим.

Pre-commit check можно использовать например так:

- выполнять проверку кода на валидность (например: соответствие требованиям PEP8, наличие документации итд);
- выполнять комплексную проверку проекта (юнит-тесты итд);
- прерывать операцию commit'а в случае обнаружения ошибок и отображать подробный журнал для разбора полетов.


## Что такое Git Flow

- [Gitflow Workflowl](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow)
- [Read Git Flow](https://leanpub.com/git-flow/read)

**Historical Branches**
Вместо использования только одной master ветки, этот workflow использует две ветки, для записи истории проекта. Master хранит официальную историю релизов, в development же ветке ведется активная разработка. Также важно тагать комиты в master ветки номерами версий.

**Feature Branches**
Каждая новая фича должна разрабатываться отдельно - в своей ветке, которая должна пушиться в центральный репозиторий для сохранения работы или коллаборации с другими разработчиками. Для создания фичебранча используется development ветка. Когда разработка фичи закончена, она сливается в development. Фичи никогда не должны сливаться напрямую с master веткой.

**Release Branches**
Как только development наберет достаточно фич для релиза (или в заранее определенную дату) создается release ветка из development ветки.

Создание этого бранча начинает новый релиз-цикл, поэтому в эту ветку уже не должно покадать никаких новых фич - только баг-фиксы, генерация документации и другие таски, ориентированные на релиз.

Как только релиз-ветка подготовлена, ее сливают с master и тагают новой версией. Также она должна быть слита и с development веткой, которая уже скорее всего убежала вперед, с момента инициализации релиза.

Использование отдельной ветки для релиза позволяет одной команде готовить релиз, в том время когда другая команда будет продолжать разрабатывать новые фичи в development для последующих релизов.

**Hotfix Branches**
Hotfix ветки используются для быстрого патчинга релизов. Это единственная ветка, которая создается из master. Как только фикс готов, он должен быть слит как в master, так и в development (или в новый release, если она есть) и master должен быть тегирован новой версией (инкрементирована patch цифра. v.1.0.1, например)

Это позволяет исправлять ошибки не прерывая весь воркфлоу или не дожидаясь следующего релиза, для выкатывания исправлений.

---

# Docker

## Что такое контейнеризация? Зачем она нужна?
Контейнеризация — это технология, которая помогает запускать приложения изолированно от основной операционной системы. Программа упаковывается в специальную оболочку-контейнер, внутри которой — среда, необходимая для работы.

Технология нужна для:

1. для изолированного запуска приложений и рабочих сред вне зависимости от системы и ПО, установленных на конкретной машине;
2. контроля ресурсов и снижения нагрузки на систему;
3. разрешения конфликтов, которые могут возникнуть из-за того, что разные приложения нуждаются в различных версиях ПО или библиотек;
4. быстрого перемещения настроенных приложений и сред с одной машины на другую;
5. создания удобной рабочей инфраструктуры;
6. ускорения процесса разработки и снижения риска ошибок;
7. масштабирования готовых решений;
8. легкого управления сложными приложениями, средами и системами. 

## Чем контейнер отличается от виртуальной машины?
Основное различие контейнеров и виртуальных машин заключается в том, что виртуальные машины виртуализируют весь компьютер вплоть до аппаратных уровней, а контейнеры — только программные уровни выше уровня операционной системы.

## Что такое образ?
Image. Неизменяемый файл (образ), из которого можно неограниченное количество раз развернуть контейнер.

Образ Docker (Docker Image) - это неизменяемый файл, содержащий исходный код, библиотеки, зависимости, инструменты и другие файлы, необходимые для запуска приложения.

Из-за того, что образы предназначены только для чтения их иногда называют снимками (snapshot).Они представляют приложение и его виртуальную среду в определенный момент времени. Такая согласованность является одной из отличительных особенностей Docker. Он позволяет разработчикам тестировать и экспериментировать программное обеспечение в стабильных, однородных условиях.

## Что такое том?
Том Docker — это средство для постоянного хранения информации на виртуальной машине. Данные в томе хранятся независимо от контейнеров. Если вы удалите контейнер, тома и данные в томах останутся. Удаление тома — отдельная операция.

Тома для постоянного хранения информации. По умолчанию в Docker папки хранилищ создаются на хост-машине, но предусмотрена и возможность подключения удаленных хранилищ

## Что такое сеть контейнера?
Сеть Docker в основном используется для установления связи между контейнерами Docker и внешним миром через хост-машину, или вы можете сказать, что это коммуникационный канал, через который все изолированные контейнеры взаимодействуют друг с другом в различных ситуациях для выполнения необходимых действий.

## Какие виды сетей бывают?

1. Bridge network при запуске Docker автоматически создается сеть типа мост по умолчанию. Недавно запущенные контейнеры будут автоматически подключаться к нему. Вы также можете создавать пользовательские настраиваемые мостовые сети. Пользовательские мостовые сети превосходят сетевые мосты по умолчанию.
2. Host network : удаляет сетевую изоляцию между контейнером и хостом Docker и напрямую использует сеть хоста. Если вы запускаете контейнер, который привязывается к порту 80, и вы используете хост-сеть, приложение контейнера доступно через порт 80 по IP-адресу хоста. Означает, что вы не сможете запускать несколько веб-контейнеров на одном хосте, на одном и том же порту, так как порт теперь является общим для всех контейнеров в сети хоста.
3. None network : в сети такого типа контейнеры не подключены ни к одной сети и не имеют доступа к внешней сети или другим контейнерам. Итак, эта сеть используется, когда вы хотите полностью отключить сетевой стек в контейнере.
4. Overlay network : Создает внутреннюю частную сеть, которая охватывает все узлы, участвующие в кластере swarm. Таким образом, оверлейные сети облегчают обмен данными между сервисом Docker Swarm и автономным контейнером или между двумя автономными контейнерами на разных демонах Docker.
5. Macvlan network : Некоторые приложения, особенно устаревшие приложения, отслеживающие сетевой трафик, ожидают прямого подключения к физической сети. В такой ситуации вы можете использовать сетевой драйвер Macvlan для назначения MAC-адреса виртуальному сетевому интерфейсу каждого контейнера, что делает его физическим сетевым интерфейсом, напрямую подключенным к физической сети.

[🐳 Объяснение концепции сетей в Docker – IT is good](https://itisgood.ru/2019/10/29/objasnenie-koncepcii-setej-v-docker/)

---
## Зачем нужен docker-compose?
В составе Docker есть инструмент, который позволяет централизованно запускать большое количество сервисов: Docker Compose. Документирование и конфигурирование сервисов приложения осуществляется с помощью текстового YAML-файла. Команда docker‑compose up развертывает сервисы приложений и создает из образа новые контейнеры, а также сети, тома и все конфигурации, указанные в файле Docker Compose.

На этапе тестирования разработчикам приходится создавать изолированные среды, а потом уничтожать их. Docker Compose позволяет создать и уничтожить среду путем ввода нескольких команд. К участию в проекте можно привлекать и сторонних пользователей.

## Оркестрация
Когда контейнеров становится слишком много, ими трудно управлять. На помощь приходят системы оркестрации.

### Docker Swarm
Стандартная система оркестрации контейнеров, достаточная для решения базовых задач. Позволяет быстро создать из нескольких хостов с контейнерами последовательный кластер Swarm, считая все кластерные хосты единым контейнерным пространством. В Docker-кластере должна быть как минимум одна управляющая нода (manager).

### Kubernetes
Платформа для автоматизации работы с контейнерами на Ubuntu, CentOS и других ОС Linux. Позволяет централизованно группировать контейнеры, балансировать нагрузку, активировать сервисы из сотен приложений одновременно. Kubernetes предоставляет пользователям больше возможностей по сравнению со Swarm, но и настраивать его сложнее.»

- RabbitMQ - [Хабр](https://habr.com/ru/post/149694/)
- Docker - [Хабр](https://habr.com/ru/company/ruvds/blog/438796/)
